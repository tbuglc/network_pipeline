{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as ss\n",
    "import numpy as np\n",
    "from manager.data import DataManager\n",
    "from factory.classfication_factory import ClassificationFactory\n",
    "from factory.regression_factory import RegressionFactory\n",
    "from constants.classification_models import ClassificationModels\n",
    "from constants.regression_models import RegressionModels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1038) (880, 1038)\n"
     ]
    }
   ],
   "source": [
    "data_manager = DataManager(min_sample_label=10)\n",
    "\n",
    "data, x_train, x_val, t_train, t_val, = data_manager.get_data()\n",
    "\n",
    "# accorderie = [[633, 6865, 10, 0, 0.02, 4.04, 0.05, 4.86, 0.06, 75.33]]\n",
    "accorderie = np.array([[0,100.0,500.0,7.0,0.0,0.0505050505050505,3.263549415515409,0.124,5.24,0.153466632043625,61.42,2.0,1.0,2.0,1.0,2.0,1.0,2.0,1.0,4.0,2.0,4.0,2.0,2.0,1.0,2.0,1.0,4.0,2.0,2.0,1.0,2.0,1.0,2.0,1.0,2.0,1.0,2.0,1.0,2.0,1.0,2.0,1.0,2.0,1.0,2.0,1.0,2.0,1.0,4.0,2.0,3.0,2.0,2.0,1.0,4.0,2.0,2.0,1.0,11.0,6.0,6.0,3.0,2.0,1.0,2.0,1.0,2.0,1.0,6.0,3.0,4.0,2.0,2.0,1.0,2.0,1.0,6.0,3.0,4.0,2.0,7.0,4.0,2.0,1.0,2.0,1.0,4.0,2.0,4.0,2.0,2.0,1.0,4.0,2.0,2.0,1.0,2.0,1.0,4.0,2.0,6.0,3.0,2.0,1.0,2.0,1.0,2.0,1.0,4.0,2.0,2.0,1.0,2.0,1.0,3.0,2.0,6.0,3.0,2.0,1.0,4.0,2.0,2.0,1.0,4.0,2.0,8.0,4.0,5.0,3.0,4.0,2.0,4.0,2.0,2.0,1.0,8.0,4.0,7.0,4.0,4.0,2.0,2.0,1.0,2.0,1.0,7.0,4.0,4.0,2.0,9.0,5.0,6.0,3.0,4.0,2.0,6.0,3.0,10.0,5.0,2.0,1.0,6.0,3.0,4.0,2.0,4.0,3.0,4.0,2.0,4.0,2.0,4.0,2.0,6.0,3.0,2.0,1.0,2.0,1.0,10.0,5.0,4.0,2.0,6.0,3.0,8.0,4.0,8.0,4.0,14.0,7.0,12.0,6.0,4.0,2.0,4.0,2.0,8.0,4.0,6.0,3.0,8.0,4.0,4.0,2.0,4.0,2.0,4.0,2.0,4.0,2.0,11.0,6.0,2.0,1.0,10.0,5.0,6.0,3.0,7.0,4.0,6.0,3.0,6.0,3.0,2.0,1.0,2.0,1.0,8.0,4.0,8.0,4.0,10.0,5.0,6.0,3.0,9.0,5.0,7.0,4.0,10.0,5.0,9.0,5.0,4.0,2.0,14.0,7.0,10.0,5.0,4.0,2.0,6.0,3.0,2.0,1.0,8.0,4.0,6.0,3.0,8.0,4.0,4.0,2.0,6.0,3.0,4.0,2.0,4.0,2.0,2.0,1.0,6.0,3.0,4.0,2.0,4.0,2.0,2.0,1.0,8.0,5.0,7.0,4.0,14.0,7.0,6.0,3.0,6.0,3.0,10.0,5.0,14.0,8.0,11.0,6.0,2.0,1.0,6.0,3.0,14.0,7.0,8.0,4.0,6.0,3.0,2.0,1.0,6.0,3.0,13.0,7.0,5.0,3.0,5.0,3.0,12.0,7.0,8.0,4.0,12.0,6.0,8.0,4.0,8.0,4.0,15.0,8.0,10.0,5.0,12.0,6.0,8.0,4.0,11.0,6.0,10.0,5.0,6.0,3.0,11.0,6.0,9.0,5.0,11.0,6.0,2.0,1.0,14.0,7.0,2.0,1.0,2.0,1.0,4.0,2.0,8.0,4.0,8.0,4.0,8.0,4.0,8.0,4.0,2.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.333333333333333,0.3333333333333333,0.7777777777777777,0.3333333333333333,0.0,1.0,0.0,2.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.090909090909091,0.09090909090909091,0.9393939393939393,0.09090909090909091,0.0,0.6363636363636364,0.0,1.333333333333333,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666666,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.142857142857143,0.5,0.9047619047619048,0.1428571428571429,0.0,0.4285714285714285,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666666,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.333333333333333,0.3333333333333333,0.7777777777777777,0.3333333333333333,0.0,1.0,0.0,2.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.2,0.2,0.8666666666666666,0.2,0.0,0.8,0.0,1.666666666666667,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.142857142857143,0.1428571428571428,0.9047619047619048,0.1428571428571428,0.0,0.7142857142857143,0.0,1.5,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.142857142857143,0.1428571428571428,0.9047619047619048,0.1428571428571428,0.0,0.7142857142857143,0.0,1.5,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.111111111111111,0.1111111111111111,0.9259259259259258,0.1111111111111111,0.0,0.6666666666666666,0.0,1.4,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666666,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.5,0.5,0.625,0.25,0.0,1.5,0.0,3.333333333333333,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.07142857142857141,0,0.5,0.0,1.0,1.0,0.5,1.0,0.08333333333333333,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666666,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.090909090909091,0.5,0.9393939393939393,0.09090909090909091,0.0,0.5454545454545454,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.09999999999999999,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666666,0,0.5,0.0,1.0,1.142857142857143,0.1428571428571428,0.9047619047619048,0.1428571428571428,0.0,0.7142857142857143,0.0,1.5,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.09999999999999999,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.111111111111111,0.5,0.9259259259259258,0.1111111111111111,0.0,0.5555555555555556,0.0,1.0,1.142857142857143,0.1428571428571428,0.9047619047619048,0.1428571428571428,0.0,0.7142857142857143,0.0,1.5,1.0,0.5,1.0,0.09999999999999998,0,0.5,0.0,1.0,1.111111111111111,0.5,0.9259259259259258,0.1111111111111111,0.0,0.4444444444444444,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.07142857142857141,0,0.5,0.0,1.0,1.0,0.5,1.0,0.09999999999999998,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.25,0.125,0.8333333333333333,0.125,0.0,0.625,0.0,1.4,1.142857142857143,0.1428571428571428,0.9047619047619049,0.1428571428571428,0.0,0.7142857142857143,0.0,1.5,1.0,0.5,1.0,0.07142857142857141,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.09999999999999999,0,0.5,0.0,1.0,1.142857142857143,0.07142857142857142,0.9047619047619048,0.07142857142857142,0.0,0.6428571428571429,0.0,1.25,1.090909090909091,0.5,0.9393939393939393,0.09090909090909088,0.0,0.4545454545454545,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.07142857142857141,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.076923076923077,0.07692307692307693,0.9487179487179487,0.07692307692307691,0.0,0.6153846153846154,0.0,1.285714285714286,1.2,0.5,0.8666666666666666,0.2,0.0,0.4,0.0,1.0,1.2,0.2,0.8666666666666666,0.2,0.0,0.8,0.0,1.666666666666667,1.166666666666667,0.1666666666666667,0.875,0.08333333333333333,0.0,0.8333333333333334,0.0,2.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.08333333333333333,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.066666666666667,0.06666666666666667,0.9555555555555555,0.06666666666666668,0.0,0.6,0.0,1.25,1.0,0.5,1.0,0.09999999999999998,0,0.5,0.0,1.0,1.0,0.5,1.0,0.08333333333333333,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.090909090909091,0.5,0.9393939393939393,0.09090909090909088,0.0,0.4545454545454545,0.0,1.0,1.0,0.5,1.0,0.09999999999999999,0,0.5,0.0,1.0,1.0,0.5,1.0,0.1666666666666667,0,0.5,0.0,1.0,1.090909090909091,0.09090909090909091,0.9393939393939393,0.09090909090909088,0.0,0.6363636363636364,0.0,1.333333333333333,1.111111111111111,0.5,0.9259259259259258,0.1111111111111111,0.0,0.5555555555555556,0.0,1.0,1.090909090909091,0.09090909090909091,0.9393939393939393,0.0909090909090909,0.0,0.6363636363636364,0.0,1.333333333333333,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.07142857142857141,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0,1.0,0.5,1.0,0.25,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.125,0,0.5,0.0,1.0,1.0,0.5,1.0,0.5,0,0.5,0.0,1.0]])\n",
    "\n",
    "\n",
    "training_set_size = x_train.shape[1]\n",
    "accorderie_size = np.array(accorderie).shape[1]\n",
    "\n",
    "if training_set_size > accorderie_size:\n",
    "    diff = training_set_size - accorderie_size\n",
    "    accorderie = np.array([np.concatenate([accorderie[0],np.zeros(diff)])])\n",
    "else:\n",
    "    accorderie = np.array([accorderie[0][:x_train.shape[1]]])\n",
    "\n",
    "print(accorderie.shape, x_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNetRegression\n",
      "     0    1    2    3    4    5         6         7         8\n",
      "0  0.3  1.0  1.0  1.0  1.0  1.0  0.285909  0.284886  0.601984\n",
      "1  0.7  0.3  0.7  1.0  1.0  1.0  0.285909  0.284886  0.540750\n",
      "2  0.4  0.8  0.7  1.0  1.0  1.0  0.285909  0.284886  0.528248\n",
      "3  0.8  0.2  0.8  1.0  1.0  1.0  0.285909  0.284886  0.552438\n",
      "4  0.0  0.0  0.0  1.0  1.0  1.0  0.285909  0.284886  0.453573\n",
      "err:  0.35517302040584436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.28590909, 0.28488636, 6.22115044]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionFactory.get_model(RegressionModels.ELASTIC_NET)\n",
    "\n",
    "model.train(x_train=x_train,x_val=x_val,t_train=t_train,t_val=t_val)\n",
    "model.predict(x_val=accorderie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegression\n",
      "     0    1    2    3    4    5    6    7    8\n",
      "0  0.3  1.0  1.0  1.0  1.0  1.0  0.3  0.7  1.0\n",
      "1  0.7  0.3  0.7  1.0  1.0  1.0  0.8  0.2  0.6\n",
      "2  0.4  0.8  0.7  1.0  1.0  1.0  0.5  0.7  0.6\n",
      "3  0.8  0.2  0.8  1.0  1.0  1.0  0.8  0.3  0.9\n",
      "4  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0\n",
      "err:  0.05469696969696967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionFactory.get_model(RegressionModels.DECISION_TREE)\n",
    "\n",
    "model.train(x_train=x_train,x_val=x_val,t_train=t_train,t_val=t_val)\n",
    "model.predict(x_val=accorderie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LasoRegressione Model\n",
      "     0    1    2    3    4    5         6         7         8\n",
      "0  0.3  1.0  1.0  1.0  1.0  1.0  0.285909  0.284886  0.526818\n",
      "1  0.7  0.3  0.7  1.0  1.0  1.0  0.285909  0.284886  0.526818\n",
      "2  0.4  0.8  0.7  1.0  1.0  1.0  0.285909  0.284886  0.526818\n",
      "3  0.8  0.2  0.8  1.0  1.0  1.0  0.285909  0.284886  0.526818\n",
      "4  0.0  0.0  0.0  1.0  1.0  1.0  0.285909  0.284886  0.526818\n",
      "err:  0.3783429752066116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.28590909, 0.28488636, 0.52681818]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionFactory.get_model(RegressionModels.LASO)\n",
    "\n",
    "model.train(x_train=x_train,x_val=x_val,t_train=t_train,t_val=t_val)\n",
    "model.predict(x_val=accorderie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegression\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m RegressionFactory\u001b[39m.\u001b[39mget_model(RegressionModels\u001b[39m.\u001b[39mRANDOM_FOREST)\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mtrain(x_train\u001b[39m=\u001b[39;49mx_train,x_val\u001b[39m=\u001b[39;49mx_val,t_train\u001b[39m=\u001b[39;49mt_train,t_val\u001b[39m=\u001b[39;49mt_val)\n\u001b[0;32m      4\u001b[0m model\u001b[39m.\u001b[39mpredict(x_val\u001b[39m=\u001b[39maccorderie)\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\projects\\school\\network_pipeline\\graph_machine_learning\\models\\base\\base_model.py:85\u001b[0m, in \u001b[0;36mBaseModel.train\u001b[1;34m(self, x_train, x_val, t_train, t_val)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mTrain the machine learning model on the training data and evaluate it on the validation data.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mtuple: A tuple containing the predicted labels for the validation data and the err score of the model.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39m# Train the model on the training data\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(x_train\u001b[39m=\u001b[39;49mx_train, t_train\u001b[39m=\u001b[39;49mt_train)\n\u001b[0;32m     86\u001b[0m \u001b[39m# Use the trained model to predict the labels of the validation data\u001b[39;00m\n\u001b[0;32m     87\u001b[0m t_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(x_val\u001b[39m=\u001b[39mx_val)\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\projects\\school\\network_pipeline\\graph_machine_learning\\models\\base\\base_model.py:32\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[1;34m(self, x_train, t_train)\u001b[0m\n\u001b[0;32m     30\u001b[0m x_train_std \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mfit_transform(x_train)\n\u001b[0;32m     31\u001b[0m \u001b[39m# Fit the scaled data and labels to the model\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(x_train_std, t_train)\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bugl2301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RegressionFactory.get_model(RegressionModels.RANDOM_FOREST)\n",
    "\n",
    "model.train(x_train=x_train,x_val=x_val,t_train=t_train,t_val=t_val)\n",
    "model.predict(x_val=accorderie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeRegressionl\n",
      "     0    1    2    3    4    5         6         7         8\n",
      "0  0.3  1.0  1.0  1.0  1.0  1.0  0.273684  0.962511  0.998222\n",
      "1  0.7  0.3  0.7  1.0  1.0  1.0  0.547760  0.671676  0.683041\n",
      "2  0.4  0.8  0.7  1.0  1.0  1.0  0.445369  0.868847  0.715650\n",
      "3  0.8  0.2  0.8  1.0  1.0  1.0  0.758729  0.237631  0.784300\n",
      "4  0.0  0.0  0.0  1.0  1.0  1.0 -0.036772 -0.232032  0.026490\n",
      "err:  0.12186584413541035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[19.59696584,  9.72658211,  2.02521912]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionFactory.get_model(RegressionModels.RIDGE)\n",
    "\n",
    "model.train(x_train=x_train,x_val=x_val,t_train=t_train,t_val=t_val)\n",
    "model.predict(x_val=accorderie)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5e2dd1cbe1f4896ca9eed4774742727d8fbcd7dc034097265272ce394987b5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
