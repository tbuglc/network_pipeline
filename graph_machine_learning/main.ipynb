{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as ss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from manager.data import DataManager\n",
    "from factory.classfication_factory import ClassificationFactory\n",
    "from factory.regression_factory import RegressionFactory\n",
    "from constants.classification_models import ClassificationModels\n",
    "from constants.regression_models import RegressionModels\n",
    "import csv\n",
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./combined_data.csv',header=None)\n",
    "targets = pd.read_csv('./combined_targets.csv',header=None)\n",
    "\n",
    "# data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.28 GiB for an array with shape (63178, 9096) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Standardize the data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 3\u001b[0m X_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(data)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Create a PCA instance and fit to the standardized data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)  \u001b[39m# We'll reduce to 2 dimensions for visualization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 824\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:946\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    943\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_seen_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39misnan(X)\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    945\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 946\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_seen_ \u001b[39m=\u001b[39m _incremental_mean_and_var(\n\u001b[0;32m    947\u001b[0m             X,\n\u001b[0;32m    948\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean_,\n\u001b[0;32m    949\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvar_,\n\u001b[0;32m    950\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_samples_seen_,\n\u001b[0;32m    951\u001b[0m             sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    952\u001b[0m         )\n\u001b[0;32m    954\u001b[0m \u001b[39m# for backward-compatibility, reduce n_samples_seen_ to an integer\u001b[39;00m\n\u001b[0;32m    955\u001b[0m \u001b[39m# if the number of samples is the same for each feature (i.e. no\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[39m# missing values)\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mptp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_seen_) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:1041\u001b[0m, in \u001b[0;36m_incremental_mean_and_var\u001b[1;34m(X, last_mean, last_variance, last_sample_count, sample_weight)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     new_sample_count \u001b[39m=\u001b[39m _safe_accumulator_op(\n\u001b[0;32m   1038\u001b[0m         np\u001b[39m.\u001b[39msum, sample_weight[:, \u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m (\u001b[39m~\u001b[39mX_nan_mask), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m   1039\u001b[0m     )\n\u001b[0;32m   1040\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1041\u001b[0m     new_sum \u001b[39m=\u001b[39m _safe_accumulator_op(sum_op, X, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m   1042\u001b[0m     n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1043\u001b[0m     new_sample_count \u001b[39m=\u001b[39m n_samples \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39msum(X_nan_mask, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:963\u001b[0m, in \u001b[0;36m_safe_accumulator_op\u001b[1;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m     result \u001b[39m=\u001b[39m op(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 963\u001b[0m     result \u001b[39m=\u001b[39m op(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    964\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnansum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:722\u001b[0m, in \u001b[0;36mnansum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_nansum_dispatcher)\n\u001b[0;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnansum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m    625\u001b[0m            initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m    626\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[39m    Return the sum of array elements over a given axis treating Not a\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39m    Numbers (NaNs) as zero.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    720\u001b[0m \n\u001b[0;32m    721\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 722\u001b[0m     a, mask \u001b[39m=\u001b[39m _replace_nan(a, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m    723\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, keepdims\u001b[39m=\u001b[39mkeepdims,\n\u001b[0;32m    724\u001b[0m                   initial\u001b[39m=\u001b[39minitial, where\u001b[39m=\u001b[39mwhere)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:107\u001b[0m, in \u001b[0;36m_replace_nan\u001b[1;34m(a, val)\u001b[0m\n\u001b[0;32m    104\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(a, subok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    108\u001b[0m     np\u001b[39m.\u001b[39mcopyto(a, val, where\u001b[39m=\u001b[39mmask)\n\u001b[0;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m a, mask\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.28 GiB for an array with shape (63178, 9096) and data type float64"
     ]
    }
   ],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "# Create a PCA instance and fit to the standardized data\n",
    "pca = PCA(n_components=2)  # We'll reduce to 2 dimensions for visualization\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Visualize Results with Multi-Dimensional Numerical Targets\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use color to represent different dimensions of the targets\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=targets, cmap='viridis', s=100)\n",
    "\n",
    "# Add a colorbar to show the scale of the target dimensions\n",
    "colorbar = plt.colorbar()\n",
    "colorbar.set_label('Target Dimensions')\n",
    "\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA Scatter Plot with Multi-Dimensional Targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50542, 9096) (12636, 9096) (50542, 3) (12636, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, t_train, t_val = train_test_split(data, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape, x_val.shape, t_train.shape, t_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_30 = [632,6864,10,0,0.01721198,4.036756267,0.048368298,4.857594937,0.056760724,83.19522305,2,2,2,1,2,1,4,4,2,3,3,2,2,1,2,1,2,1,2,2,2,2,2,1,2,1,2,1,4,3,6,6,4,2,4,2,4,4,2,1,6,3,2,1,5,4,2,1,2,1,2,1,3,2,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,4,11,11,8,11,9,7,7,9,7,9,3,2,2,1,10,5,15,15,31,36,28,27,33,35,31,36,43,65,38,31,30,36,39,54,33,50,40,46,44,45,45,56,43,52,47,63,37,49,38,39,55,60,54,82,35,47,46,71,44,70,44,73,59,91,67,108,45,75,53,55,64,68,60,70,66,91,54,86,41,47,55,76,50,62,45,60,56,97,58,107,56,85,46,85,56,94,61,115,44,69,40,39,31,20,16,9,36,30,39,32,47,46,53,42,36,38,34,37,39,75,54,115,52,93,56,91,60,71,56,87,36,78,60,130,78,167,63,114,54,98,46,76,46,80,53,99,43,78,45,72,32,42,26,48,40,58,39,52,55,64,49,67,50,68,34,46,36,53,36,58,27,56,29,53,52,72,28,33,38,67,43,86,30,76,34,73,31,53,25,37,32,42,32,55,26,58,33,61,39,70,19,37,25,48,34,53,38,80,37,83,39,65,29,52,26,40,29,57,25,48,33,55,35,66,21,28,43,86,57,121,2,0.5,0.5,0.5,0,0.5,0,0.5,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,2,0.5,0.53125,0.25,0,0.25,0,0.75,3,0.5,0.333333333,0.5,0,0.5,0,0.333333333,1.333333333,0.5,0.777777778,0.333333333,0,0.333333333,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,2,0.5,0.5,0.5,0,0.5,0,0.5,2,0.5,0.5,0.5,0,0.5,0,0.5,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1.5,0.5,0.7,0.25,0,0.25,0,1,2,0.5,0.487932547,0.166666667,0,0.333333333,0,0.833333333,1,0.5,1,0.25,0,0.5,0,1,1,0.5,1,0.25,0,0.5,0,1,2,0.5,0.49047619,0.25,0,0.5,0,0.75,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.166666667,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1.6,0.5,0.657142857,0.2,0,0.2,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1.333333333,0.5,0.777777778,0.333333333,0,0.333333333,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,4,0.5,0.25,0.5,0,0.5,0,0.25,2,0.5,0.539393939,0.090909091,0,0.181818182,0,0.818181818,2.75,0.5,0.3828125,0.125,0,0.25,0,0.545454545,1.555555556,0.5,0.679012346,0.111111111,0,0.222222222,0,1,2.571428571,0.5,0.41424991,0.142857143,0,0.142857143,0,0.666666667,2.571428571,0.5,0.41424991,0.142857143,0,0.142857143,0,0.666666667,1.333333333,0.5,0.777777778,0.333333333,0,0.333333333,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.1,0,0.5,0,1,2,0.066666667,0.621825397,0.066666667,0.166666667,0.533333333,0,0.822222222,2.322580645,0.072580645,0.411824716,0.032258065,0,1,0,2,1.928571429,0.103174603,0.538896148,0.035714286,0,1.071428571,0,2.222222222,2.121212121,0.04040404,0.395833135,0.03030303,0,0.878787879,0,1.314285714,2.322580645,0.075268817,0.501834192,0.032258065,0.085714286,0.741935484,0,1.083333333,3.023255814,0.046798737,0.410000249,0.023255814,0.05027933,0.953488372,0,1.578461538,1.631578947,0.065789474,0.633881045,0.026315789,0.0625,0.657894737,0,1.290322581,2.4,0.104166667,0.368624257,0.033333333,0,1.066666667,0,2.055555556,2.769230769,0.087606838,0.499938995,0.025641026,0.050847458,1.025641026,0,1.728395062,3.03030303,0.095959596,0.28968606,0.03030303,0.0375,1.121212121,0,1.38,2.3,0.1,0.452052454,0.025,0,1.05,0,1.47826087,2.045454545,0.095454545,0.446498292,0.022727273,0.046875,0.954545455,0,1.711111111,2.488888889,0.058666667,0.33382398,0.022222222,0,1.377777778,0,2.625,2.418604651,0.093023256,0.426931187,0.023255814,0.035087719,0.860465116,0,1.096153846,2.680851064,0.044680851,0.419050786,0.021276596,0,0.936170213,0,1.301587302,2.648648649,0.058968059,0.564307145,0.027027027,0.096774194,0.945945946,0,1.142857143,2.052631579,0.105263158,0.619900449,0.026315789,0,0.947368421,0,1.435897436,2.181818182,0.068181818,0.444099274,0.018181818,0.026785714,0.945454545,0,1.283333333,3.037037037,0.041666667,0.454235921,0.018518519,0.03030303,0.888888889,0,0.780487805,2.685714286,0.06031746,0.472647941,0.028571429,0,0.971428571,0,1.319148936,3.086956522,0.046195652,0.505407987,0.02173913,0.04109589,1,0,1.450704225,3.181818182,0.072860963,0.468400452,0.022727273,0.096774194,1.477272727,0,2.9,3.318181818,0.05785124,0.355207523,0.022727273,0.050420168,1.431818182,0,1.904109589,3.084745763,0.079096045,0.404379071,0.016949153,0.024590164,0.949152542,0,1.10989011,3.223880597,0.054274084,0.327647625,0.014925373,0.048543689,1.104477612,0,1.287037037,3.333333333,0.044444444,0.357810173,0.022222222,0.023076923,1.022222222,0,1.08,2.075471698,0.06918239,0.622206912,0.018867925,0,0.773584906,0,1.109090909,2.125,0.0625,0.401749459,0.015625,0.028571429,1.515625,0,5.735294118,2.333333333,0.072222222,0.498856967,0.016666667,0.037974684,0.85,0,1.1,2.757575758,0.058802309,0.465098296,0.015151515,0.05033557,1.060606061,0,1.608058608,3.185185185,0.080246914,0.432457091,0.018518519,0.022556391,1.018518519,0,0.872093023,2.292682927,0.082926829,0.469350036,0.024390244,0.110091743,0.975609756,0,1.574468085,2.763636364,0.042506143,0.397024847,0.018181818,0.04,2.509090909,0,4.263157895,2.48,0.108,0.42460833,0.02,0.049450549,1.44,0,2.193548387,2.666666667,0.127777778,0.305658781,0.022222222,0.043478261,1.066666667,0,1.416666667,3.464285714,0.064868805,0.264359541,0.017857143,0.042857143,1.357142857,0,1.756013746,3.689655172,0.048692687,0.380690299,0.017241379,0.067988669,1.068965517,0,1.221628838,3.035714286,0.080357143,0.343554852,0.017857143,0.013100437,0.928571429,0,1.023529412,3.695652174,0.050343249,0.308449916,0.02173913,0.014150943,1.152173913,0,1.423529412,3.357142857,0.056657848,0.357205121,0.017857143,0.02955665,1.035714286,0,1.321985816,3.770491803,0.078347882,0.383121637,0.016393443,0.030379747,1.098360656,0,1.056126482,3.136363636,0.147727273,0.334815989,0.022727273,0.025210084,1.090909091,0,1.31884058,1.95,0.05,0.620362449,0.025,0,0.75,0,0.897435897,1.290322581,0.032258065,0.833333333,0.032258065,0,0.677419355,0,1.15,1.125,0.5,0.9375,0.0625,0,0.5,0,0.888888889,1.666666667,0.083333333,0.690952329,0.027777778,0,0.666666667,0,1.033333333,1.641025641,0.051282051,0.681954506,0.025641026,0,0.641025641,0,1,1.957446809,0.070921986,0.471576652,0.021276596,0,0.808510638,0,1.260869565,1.58490566,0.044025157,0.598550274,0.018867925,0,0.79245283,0,2.214285714,2.111111111,0.069444444,0.55392547,0.027777778,0,0.722222222,0,0.947368421,2.176470588,0.12254902,0.324372819,0.029411765,0,1.117647059,0,2.081081081,3.846153846,0.102564103,0.34517844,0.025641026,0.022222222,1.025641026,0,0.906666667,4.259259259,0.070707071,0.238693323,0.018518519,0.050167224,1.055555556,0,1.130434783,3.576923077,0.047552448,0.408020059,0.019230769,0.086538462,1.173076923,0,1.444444444,3.25,0.084821429,0.330134131,0.017857143,0.044776119,1.071428571,0,1.318681319,2.366666667,0.072727273,0.431882588,0.016666667,0,0.95,0,1.352112676,3.107142857,0.04952381,0.317192593,0.017857143,0.012396694,1.303571429,0,2.436781609,4.333333333,0.118055556,0.32035167,0.027777778,0.043478261,1.083333333,0,0.820512821,4.333333333,0.041666667,0.400737822,0.016666667,0,0.95,0,0.630769231,4.282051282,0.057692308,0.379338725,0.012820513,0.012269939,0.820512821,0,0.604790419,3.619047619,0.057720058,0.303328537,0.015873016,0,1.047619048,0,1.570175439,3.62962963,0.107407407,0.283403325,0.018518519,0.026785714,1.055555556,0,1.112244898,3.304347826,0.108695652,0.450918815,0.02173913,0.057971014,0.934782609,0,1.026315789,3.47826087,0.062111801,0.304428648,0.02173913,0.043165468,1.434782609,0,1.875,3.735849057,0.058216417,0.261550187,0.018867925,0.062015504,1.660377358,0,2.498316498,3.627906977,0.067829457,0.353647441,0.023255814,0.012345679,1.093023256,0,1.320512821,3.2,0.125925926,0.326893539,0.022222222,0,1.111111111,0,1.041666667,2.625,0.0625,0.449523614,0.03125,0,0.84375,0,0.904761905,3.692307692,0.115384615,0.301494981,0.038461538,0,0.846153846,0,0.583333333,2.9,0.0875,0.461983321,0.025,0.014563107,0.9,0,0.844827586,2.666666667,0.057692308,0.473411809,0.025641026,0,0.846153846,0,0.961538462,2.327272727,0.045454545,0.592478846,0.018181818,0.039473684,0.672727273,0,0.796875,2.734693878,0.085034014,0.378256751,0.020408163,0,1.142857143,0,1.328358209,2.72,0.072,0.484212528,0.02,0,0.84,0,1.058823529,2.705882353,0.067474048,0.311195543,0.029411765,0,1.529411765,0,3.47826087,2.944444444,0.135416667,0.407539619,0.027777778,0,1.194444444,0,1.254716981,3.222222222,0.08994709,0.49291918,0.027777778,0.091603053,0.944444444,0,1.005747126,4.148148148,0.12037037,0.402753956,0.037037037,0.052631579,1.074074074,0,0.821428571,3.655172414,0.103448276,0.352870842,0.034482759,0.028571429,0.965517241,0,0.79245283,2.769230769,0.069230769,0.364577948,0.019230769,0.013824885,0.903846154,0,1.194444444,2.357142857,0.035714286,0.61764997,0.035714286,0.043478261,0.75,0,0.696969697,3.526315789,0.078947368,0.467442502,0.026315789,0.018072289,1,0,0.76119403,4,0.038372093,0.367258094,0.023255814,0.021377672,0.953488372,0,0.623255814,5.066666667,0.5,0.307598248,0.033333333,0,0.8,0,0.355263158,4.294117647,0.029411765,0.328511297,0.029411765,0.01986755,0.764705882,0,0.465753425,3.419354839,0.056451613,0.553408812,0.032258065,0,0.870967742,0,0.698113208,2.96,0.12,0.447139497,0.04,0,0.96,0,0.783783784,2.625,0.125,0.485243209,0.03125,0,0.8125,0,0.785714286,3.4375,0.0625,0.419764726,0.03125,0,0.90625,0,0.709090909,4.461538462,0.076923077,0.309428131,0.038461538,0,0.884615385,0,0.448275862,3.696969697,0.03030303,0.394939534,0.03030303,0,0.757575758,0,0.475409836,3.58974359,0.038461538,0.358185696,0.025641026,0,0.974358974,0,0.8,3.894736842,0.052631579,0.304799963,0.052631579,0,0.789473684,0,0.459459459,3.84,0.12,0.32722453,0.04,0.048387097,0.88,0,0.5625,3.117647059,0.088235294,0.497835596,0.029411765,0,0.911764706,0,0.698113208,4.210526316,0.078947368,0.268416726,0.026315789,0,0.789473684,0,0.5125,4.486486486,0.067567568,0.365880671,0.027027027,0.024590164,1.108108108,0,0.78313253,3.333333333,0.064102564,0.353701176,0.025641026,0.054545455,0.948717949,0,0.923076923,3.586206897,0.086206897,0.280019385,0.034482759,0,0.931034483,0,0.711538462,3.076923077,0.08974359,0.355116408,0.038461538,0,1.076923077,0,0.875,3.931034483,0.057471264,0.302556848,0.034482759,0,1.103448276,0,1.070175439,3.84,0.08,0.289526501,0.04,0,0.96,0,0.666666667,3.333333333,0.055555556,0.463854658,0.03030303,0,0.909090909,0,0.890909091,3.771428571,0.057142857,0.324864477,0.028571429,0,0.857142857,0,0.590909091,2.666666667,0.083333333,0.448377341,0.047619048,0,1,0,1.178571429,4,0.072152654,0.222143897,0.023255814,0.007109005,1.302325581,0,1.236434109,4.245614035,0.061078622,0.287022432,0.01754386,0.013081395,0.98245614,0,0.615243343]\n",
    "sn_60 = [632,6864,10,0,0.01721198,4.036756267,0.048368298,4.857594937,0.056760724,83.19522305,2,2,2,1,2,1,4,4,2,3,4,3,3,2,2,2,3,3,3,2,7,8,7,4,4,5,6,3,5,5,2,1,4,3,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,5,14,21,10,16,8,11,12,6,36,51,49,60,58,98,55,67,51,102,60,87,63,108,66,111,68,98,67,128,65,141,73,164,84,183,87,121,84,160,68,127,74,136,69,157,78,189,69,175,76,183,52,58,43,39,65,77,69,79,50,109,71,208,77,160,68,164,100,288,84,206,66,156,68,174,57,114,47,103,68,116,65,131,53,99,44,114,64,124,49,99,53,158,50,122,44,79,39,111,52,130,32,84,52,132,51,146,36,92,38,101,53,120,49,114,2,0.5,0.5,0.5,0,0.5,0,0.5,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,2,0.5,0.53125,0.25,0,0.25,0,0.75,3,0.5,0.333333333,0.5,0,0.5,0,0.333333333,1.5,0.5,0.7,0.25,0,0.25,0,1,1.333333333,0.5,0.777777778,0.333333333,0,0.333333333,0,1,2,0.5,0.5,0.5,0,0.5,0,0.5,2,0.5,0.522222222,0.333333333,0,0.333333333,0,0.666666667,1.333333333,0.5,0.777777778,0.333333333,0,0.333333333,0,1,2.285714286,0.5,0.434413957,0.142857143,0,0.285714286,0,0.75,1.142857143,0.5,0.904761905,0.142857143,0,0.428571429,0,1,2.5,0.5,0.40625,0.25,0,0.5,0,0.6,1,0.5,1,0.166666667,0,0.5,0,1,2,0.5,0.532727273,0.2,0,0.2,0,0.8,1,0.5,1,0.5,0,0.5,0,1,1.5,0.5,0.7,0.25,0,0.25,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,5,0.5,0.2,0.5,0,0.5,0,0.2,3,0.5,0.375423701,0.071428571,0,0.142857143,0,0.571428571,3.2,0.5,0.417569787,0.1,0,0.2,0,0.5,2.75,0.5,0.391687178,0.125,0,0.125,0,0.636363636,1,0.5,1,0.083333333,0,0.5,0,1,2.833333333,0.050747863,0.442048817,0.027777778,0.082568807,0.972222222,0,1.758169935,2.448979592,0.034693878,0.438004677,0.020408163,0,0.979591837,0,1.733333333,3.379310345,0.052738337,0.393264046,0.017241379,0.052631579,0.931034483,0,1.56122449,2.436363636,0.073939394,0.396789021,0.018181818,0.050420168,1.018181818,0,2.358208955,4,0.077550121,0.369845455,0.019607843,0.029126214,1.843137255,0,5.450980392,2.9,0.069871795,0.384579969,0.016666667,0.018987342,1.316666667,0,2.666666667,3.428571429,0.078869048,0.250195104,0.015873016,0.049833887,1.26984127,0,2.324074074,3.363636364,0.045789386,0.37161558,0.015151515,0.036,1.424242424,0,2.228828829,2.882352941,0.058069382,0.386520121,0.014705882,0.052083333,1.029411765,0,1.595238095,3.820895522,0.038557214,0.341332828,0.014925373,0.0375,0.955223881,0,0.9140625,4.338461538,0.057410882,0.327360901,0.015384615,0.060402685,1.753846154,0,3.687943262,4.493150685,0.07483687,0.305071177,0.01369863,0.027272727,1.780821918,0,3.150203252,4.357142857,0.061111111,0.216071866,0.011904762,0.043568465,1.154761905,0,1.234972678,2.781609195,0.062835249,0.293560521,0.011494253,0.016759777,2.137931034,0,11.81818182,3.80952381,0.056122449,0.338725199,0.011904762,0.083333333,1.357142857,0,1.83125,3.735294118,0.080882353,0.270036308,0.014705882,0.037267081,1.205882353,0,1.480314961,3.675675676,0.049735029,0.323630785,0.013513514,0.074074074,2.72972973,0,4.760294118,4.550724638,0.107246377,0.246265848,0.014492754,0.045454545,1.492753623,0,2.420382166,4.846153846,0.075312771,0.304079069,0.012820513,0.071770335,1.461538462,0,2.167548501,5.072463768,0.045294138,0.281781496,0.014492754,0.023255814,1.420289855,0,1.845079365,4.815789474,0.072124756,0.299197554,0.013157895,0.033632287,1.368421053,0,1.715846995,2.230769231,0.083333333,0.402324977,0.019230769,0,0.942307692,0,1.155172414,1.813953488,0.098837209,0.580507691,0.023255814,0,0.88372093,0,1.58974359,2.369230769,0.058461538,0.3186986,0.015384615,0.012875536,0.846153846,0,1.272727273,2.289855072,0.056590752,0.434249785,0.014492754,0.028846154,0.956521739,0,2.569620253,4.36,0.106666667,0.250160598,0.02,0.08203125,1.12,0,1.52293578,5.85915493,0.061158317,0.305645359,0.014084507,0.085152838,1.450704225,0,1.735576923,4.155844156,0.08008658,0.250712337,0.012987013,0.022556391,1.168831169,0,1.625,4.823529412,0.052965808,0.28520981,0.014705882,0.034324943,1.867647059,0,3.586328626,5.76,0.042857143,0.310941914,0.01,0.012269939,1.03,0,0.725694444,4.904761905,0.058520772,0.251713597,0.011904762,0.010380623,1.333333333,0,2.159719688,4.727272727,0.087320574,0.357180045,0.015151515,0.085510689,1.848484848,0,2.673076923,5.117647059,0.057357995,0.273635998,0.014705882,0.054698457,1.779411765,0,3.662835249,4,0.072368421,0.251869268,0.01754386,0,1.140350877,0,1.01754386,4.382978723,0.085106383,0.351971664,0.021276596,0.013953488,0.829787234,0,0.563106796,3.411764706,0.034926471,0.391781775,0.014705882,0.015706806,0.794117647,0,0.853448276,4.030769231,0.082051282,0.254528361,0.015384615,0,1.323076923,0,1.671755725,3.735849057,0.046855346,0.31048531,0.018867925,0.01369863,1.698113208,0,3.03030303,5.181818182,0.130681818,0.320017601,0.022727273,0.103448276,1.295454545,0,1.087719298,3.875,0.0546875,0.314055558,0.015625,0.028571429,1,0,1.137096774,4.040816327,0.06122449,0.462988736,0.020408163,0.038626609,0.897959184,0,0.616161616,5.962264151,0.037735849,0.305344894,0.018867925,0.016363636,0.905660377,0,0.417721519,4.88,0.04,0.350908311,0.02,0.013953488,0.82,0,0.483606557,3.590909091,0.113636364,0.368971621,0.022727273,0.017045455,0.863636364,0,0.64556962,5.692307692,0.068376068,0.293555422,0.025641026,0,0.974358974,0,0.45045045,5,0.03125,0.346917389,0.019230769,0,0.884615385,0,0.523076923,5.25,0.125,0.296902383,0.03125,0.03,0.875,0,0.416666667,5.076923077,0.057692308,0.300484752,0.019230769,0.013333333,0.846153846,0,0.568181818,5.725490196,0.092436975,0.189534603,0.019607843,0.017964072,1.352941176,0,1.082191781,5.111111111,0.072916667,0.145377684,0.027777778,0,1.277777778,0,0.782608696,5.315789474,0.085526316,0.230729588,0.026315789,0,1.447368421,0,1.346534653,4.528301887,0.061844864,0.404429693,0.018867925,0.011494253,0.962264151,0,0.705555556,4.653061224,0.065263605,0.198196812,0.020408163,0.006437768,1.551020408,0,1.82748538,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "sn_90 = [632,6864,10,0,0.01721198,4.036756267,0.048368298,4.857594937,0.056760724,83.19522305,2,2,2,1,2,1,4,4,3,5,4,3,2,4,4,3,10,10,4,2,7,8,5,5,2,1,4,4,2,1,2,1,2,1,2,1,2,1,4,2,14,25,12,25,3,2,2,1,40,56,64,96,73,130,64,148,77,151,77,149,86,185,79,213,98,271,102,190,92,215,83,196,90,282,91,281,74,127,60,71,90,124,72,221,91,251,91,291,113,371,86,252,68,189,60,155,82,192,61,155,71,180,67,181,60,198,58,133,61,186,49,136,66,223,48,146,59,166,79,233,2,0.5,0.5,0.5,0,0.5,0,0.5,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,2,0.5,0.53125,0.25,0,0.25,0,0.75,3.333333333,0.5,0.318518519,0.333333333,0,0.333333333,0,0.4,1.5,0.5,0.7,0.25,0,0.25,0,1,4,0.5,0.25,0.5,0,0.5,0,0.25,1.5,0.5,0.7,0.25,0,0.25,0,1,2,0.5,0.49361185,0.1,0,0.3,0,0.8,1,0.5,1,0.25,0,0.5,0,1,2.285714286,0.5,0.551741909,0.142857143,0,0.428571429,0,0.625,2,0.5,0.532727273,0.2,0,0.2,0,0.8,1,0.5,1,0.5,0,0.5,0,1,2,0.5,0.53125,0.25,0,0.25,0,0.75,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.25,0,0.5,0,1,3.571428571,0.5,0.362725288,0.071428571,0,0.142857143,0,0.48,4.166666667,0.5,0.354620371,0.083333333,0,0.166666667,0,0.4,1.333333333,0.5,0.777777778,0.333333333,0,0.333333333,0,1,1,0.5,1,0.5,0,0.5,0,1,2.8,0.047131148,0.461558934,0.025,0.070866142,0.925,0,1.880952381,3,0.053710938,0.384563551,0.015625,0.05033557,1.125,0,2.045138889,3.561643836,0.039274685,0.339270678,0.01369863,0.059850374,1.383561644,0,3.707692308,4.625,0.056834795,0.32702868,0.015625,0.020689655,1.96875,0,6.398648649,3.922077922,0.051908993,0.2467548,0.012987013,0.049079755,1.298701299,0,2.656953642,3.87012987,0.072294372,0.300308394,0.012987013,0.039473684,1.415584416,0,2.44966443,4.302325581,0.044573643,0.316299718,0.011627907,0.040298507,1.093023256,0,1.135135135,5.392405063,0.043008365,0.21169393,0.012658228,0.064285714,2.025316456,0,4.441314554,5.530612245,0.066391113,0.201932364,0.010204082,0.04368932,1.663265306,0,3.129151292,3.725490196,0.064327094,0.264441468,0.009803922,0.061363636,2.784313725,0,19.33157895,4.673913043,0.074671984,0.278533496,0.010869565,0.048192771,1.695652174,0,3.074418605,4.722891566,0.068328486,0.295047905,0.012048193,0.101538462,2.855421687,0,5.412585034,6.266666667,0.06393151,0.237766274,0.011111111,0.082098062,1.766666667,0,3.033930412,6.175824176,0.045991046,0.270151731,0.010989011,0.026973027,1.736263736,0,2.743772242,3.432432432,0.087162162,0.262128447,0.013513514,0.012605042,1.405405405,0,2.196850394,2.366666667,0.072222222,0.384025015,0.016666667,0,1.016666667,0,1.845070423,2.755555556,0.049544627,0.333912226,0.011111111,0.071713147,1.1,0,2.588709677,6.138888889,0.086126629,0.301803308,0.013888889,0.077586207,1.555555556,0,2.341628959,5.516483516,0.044216756,0.269171035,0.010989011,0.075250836,1.714285714,0,3.726427623,6.395604396,0.052522366,0.27991477,0.010989011,0.02241594,2.450549451,0,6.107693387,6.566371681,0.053911098,0.214761193,0.008849558,0.020512821,1.212389381,0,1.782569632,5.860465116,0.09692691,0.287831762,0.011627907,0.074433657,2.453488372,0,3.930555556,5.558823529,0.084313725,0.237888341,0.014705882,0.009836066,1.617647059,0,2.349206349,5.166666667,0.068181818,0.349065356,0.016666667,0.011070111,1,0,0.858064516,4.682926829,0.07300813,0.236323298,0.012195122,0.028391167,1.329268293,0,1.675347222,5.081967213,0.06045082,0.311495485,0.016393443,0.058659218,2,0,3.44516129,5.070422535,0.043863179,0.273791087,0.014084507,0.032258065,1.197183099,0,1.411111111,5.402985075,0.05048288,0.254706174,0.014925373,0.033057851,1.104477612,0,0.758747698,6.6,0.037060041,0.250543987,0.016666667,0.013100437,0.85,0,0.3835578,4.586206897,0.042528736,0.313704438,0.017241379,0.010309278,1.086206897,0,0.909774436,6.098360656,0.038934426,0.296029228,0.016393443,0.006479482,0.93442623,0,0.478494624,5.551020408,0.112244898,0.3427221,0.020408163,0.031413613,0.959183673,0,0.463235294,6.757575758,0.083333333,0.164376258,0.015151515,0.018404908,1.257575758,0,0.941704036,6.083333333,0.047149123,0.214940666,0.020833333,0,1.166666667,0,0.835616438,5.627118644,0.041431262,0.262090699,0.016949153,0.00931677,1.016949153,0,0.738955823,5.898734177,0.046375144,0.19950611,0.012658228,0.008975318,1.556962025,0,1.654506438,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "sn_180 = [632,6864,10,0,0.01721198,4.036756267,0.048368298,4.857594937,0.056760724,83.19522305,3,3,5,5,6,8,4,7,11,12,7,8,6,6,4,4,3,2,2,1,2,1,2,1,15,27,13,27,41,57,103,223,99,295,114,333,121,484,133,404,120,478,116,407,107,194,114,472,144,653,105,438,102,347,93,335,96,375,90,317,85,358,77,308,2,0.5,0.522222222,0.333333333,0,0.333333333,0,0.666666667,2,0.5,0.532727273,0.2,0,0.2,0,0.8,2.666666667,0.5,0.416666667,0.166666667,0,0.166666667,0,0.625,3.5,0.5,0.317927171,0.25,0,0.25,0,0.428571429,2.181818182,0.5,0.412254479,0.090909091,0,0.272727273,0,0.75,2.285714286,0.5,0.551741909,0.142857143,0,0.428571429,0,0.625,2,0.5,0.531746032,0.166666667,0,0.166666667,0,0.833333333,2,0.5,0.53125,0.25,0,0.25,0,0.75,1.333333333,0.5,0.777777778,0.333333333,0,0.333333333,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,1,0.5,1,0.5,0,0.5,0,1,3.6,0.5,0.370047835,0.066666667,0,0.133333333,0,0.481481481,4.153846154,0.5,0.34948093,0.076923077,0,0.153846154,0,0.407407407,2.780487805,0.045981607,0.45843148,0.024390244,0.0703125,0.926829268,0,1.865497076,4.330097087,0.050149071,0.352758139,0.009708738,0.06938326,1.514563107,0,5.062780269,5.95959596,0.050018821,0.297776704,0.01010101,0.055045872,2.676767677,0,12.74553672,5.842105263,0.048286279,0.244878265,0.00877193,0.059308072,2.184210526,0,5.781295581,8,0.058738456,0.193933929,0.008264463,0.063829787,6.553719008,0,49.5691706,6.07518797,0.076822092,0.203560914,0.007518797,0.086538462,5.563909774,0,46.72923704,7.966666667,0.060336272,0.259459417,0.008333333,0.091537133,4.291666667,0,19.82914923,7.017241379,0.064391876,0.272203309,0.00862069,0.04109589,2,0,5.688097188,3.626168224,0.061110652,0.242667079,0.009345794,0.068181818,1.392523364,0,3.553837342,8.280701754,0.062247966,0.257093156,0.00877193,0.084862385,3.50877193,0,16.35847458,9.069444444,0.049818139,0.212316736,0.006944444,0.033171163,2.944444444,0,9.566557281,8.342857143,0.088944584,0.211051003,0.00952381,0.052356021,3.247619048,0,6.779934044,6.803921569,0.053775577,0.224399225,0.009803922,0.01953125,1.980392157,0,7.36426513,7.204301075,0.057720054,0.294321866,0.010752688,0.056804734,3.161290323,0,10.13053305,7.8125,0.036265432,0.220042071,0.010416667,0.022823331,1.135416667,0,0.704,7.044444444,0.045555556,0.239320183,0.011111111,0.009564293,1.166666667,0,0.722397476,8.423529412,0.058467023,0.170676999,0.011764706,0.030821918,1.388235294,0,0.966480447,8,0.055549336,0.213703376,0.012987013,0.009852217,1.506493506,0,1.270995671,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "sn_210 = [632,6864,10,0,0.01721198,4.036756267,0.048368298,4.857594937,0.056760724,83.19522305,3,3,5,8,6,9,12,15,7,8,6,6,5,5,3,2,2,2,12,17,16,38,55,82,104,299,114,341,130,486,156,541,127,525,117,416,119,292,126,655,151,692,110,397,110,403,102,411,90,364,92,421,2,0.5,0.522222222,0.333333333,0,0.333333333,0,0.666666667,3.2,0.5,0.352964427,0.2,0,0.2,0,0.5,3,0.5,0.377738481,0.166666667,0,0.166666667,0,0.555555556,2.5,0.5,0.36524608,0.083333333,0,0.25,0,0.666666667,2.285714286,0.5,0.551741909,0.142857143,0,0.428571429,0,0.625,2,0.5,0.531746032,0.166666667,0,0.166666667,0,0.833333333,2,0.5,0.532727273,0.2,0,0.2,0,0.8,1.333333333,0.5,0.777777778,0.333333333,0,0.333333333,0,1,2,0.5,0.5,0.5,0,0.5,0,0.5,2.833333333,0.5,0.50122549,0.083333333,0,0.166666667,0,0.588235294,4.75,0.5,0.241702742,0.0625,0,0.125,0,0.368421053,2.981818182,0.034224599,0.420633187,0.018181818,0.064171123,0.981818182,0,2.597560976,5.75,0.048461387,0.335867978,0.009615385,0.066284779,2.75,0,18.03268036,5.98245614,0.06754657,0.289796265,0.00877193,0.075918367,4.245614035,0,23.77458456,7.476923077,0.051028416,0.240598607,0.007692308,0.065934066,5.915384615,0,22.15885264,6.935897436,0.061541842,0.210014171,0.006410256,0.069725864,4.903846154,0,33.91172352,8.267716535,0.065270969,0.25802237,0.007874016,0.099421357,4.795275591,0,30.26462132,7.111111111,0.068121918,0.269403444,0.008547009,0.047826087,2,0,5.563888889,4.907563025,0.079997216,0.277095844,0.008403361,0.067647059,1.495798319,0,4.422374429,10.3968254,0.043177496,0.184051506,0.007936508,0.058853119,3.658730159,0,15.7426397,9.165562914,0.042476503,0.214912714,0.006622517,0.044406196,2.377483444,0,7.993400771,7.218181818,0.059968992,0.195033856,0.009090909,0.029126214,1.754545455,0,2.93736356,7.327272727,0.052365645,0.322352694,0.009090909,0.051227321,3.236363636,0,13.42282878,8.058823529,0.032781863,0.217385285,0.009803922,0.018218623,1.147058824,0,0.710462287,8.088888889,0.050555556,0.180601899,0.011111111,0.014440433,1.222222222,0,0.673076923,9.152173913,0.070923913,0.202326729,0.010869565,0.01465798,1.380434783,0,1.197149644,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1065)\n",
      "9096 1065\n",
      "8031\n",
      "(1, 9096) (50542, 9096)\n"
     ]
    }
   ],
   "source": [
    "# data_manager = DataManager(min_sample_label=10)\n",
    "\n",
    "# data, x_train, x_val, t_train, t_val, = data_manager.get_data()\n",
    "\n",
    "# print(t_train)\n",
    "# accorderie = [[633, 6865, 10, 0, 0.02, 4.04, 0.05, 4.86, 0.06, 75.33]]\n",
    "accorderie = np.array([sn_90])\n",
    "print(accorderie.shape)\n",
    "training_set_size = x_train.shape[1]\n",
    "accorderie_size = accorderie.shape[1]\n",
    "print(training_set_size, accorderie_size)\n",
    "if training_set_size > accorderie_size:\n",
    "    diff = training_set_size - accorderie_size\n",
    "    print(diff)\n",
    "    accorderie = np.array([np.concatenate([accorderie[0],np.zeros(diff)])])\n",
    "else:\n",
    "    accorderie = np.array([accorderie[0][:x_train.shape[1]]])\n",
    "\n",
    "print(accorderie.shape, x_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNetRegression\n",
      "err:  0.32568409619487193\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionFactory.get_model(RegressionModels.ELASTIC_NET)\n",
    "\n",
    "model.train(x_train=x_train,x_val=x_val,t_train=t_train,t_val=t_val)\n",
    "# pred = model.predict(x_val=accorderie)\n",
    "# print(pred)\n",
    "# model.cross_validate_model_performance(x_train=x_train,t_train=t_train, cv=10)\n",
    "# model.cross_validate_prediction(x_val=x_train,t_val=t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:1047: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:1052: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.43 GiB for an array with shape (50542, 9096) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m RegressionFactory\u001b[39m.\u001b[39mget_model(RegressionModels\u001b[39m.\u001b[39mDECISION_TREE)\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mtrain(x_train\u001b[39m=\u001b[39;49mx_train,x_val\u001b[39m=\u001b[39;49mx_val,t_train\u001b[39m=\u001b[39;49mt_train,t_val\u001b[39m=\u001b[39;49mt_val)\n\u001b[0;32m      4\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_val\u001b[39m=\u001b[39maccorderie)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(pred)\n",
      "File \u001b[1;32mc:\\Users\\lucbu\\projects\\school\\network_pipeline\\graph_machine_learning\\models\\base\\base_model.py:85\u001b[0m, in \u001b[0;36mBaseModel.train\u001b[1;34m(self, x_train, x_val, t_train, t_val)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mTrain the machine learning model on the training data and evaluate it on the validation data.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mtuple: A tuple containing the predicted labels for the validation data and the err score of the model.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39m# Train the model on the training data\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(x_train\u001b[39m=\u001b[39;49mx_train, t_train\u001b[39m=\u001b[39;49mt_train)\n\u001b[0;32m     86\u001b[0m \u001b[39m# Use the trained model to predict the labels of the validation data\u001b[39;00m\n\u001b[0;32m     87\u001b[0m t_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(x_val\u001b[39m=\u001b[39mx_val)\n",
      "File \u001b[1;32mc:\\Users\\lucbu\\projects\\school\\network_pipeline\\graph_machine_learning\\models\\base\\base_model.py:30\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[1;34m(self, x_train, t_train)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mTrain the machine learning model on the training data.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m# Scale the input features\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m x_train_std \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaler\u001b[39m.\u001b[39;49mfit_transform(x_train)\n\u001b[0;32m     31\u001b[0m \u001b[39m# Fit the scaled data and labels to the model\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(x_train_std, t_train)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 824\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:946\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    943\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_seen_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39misnan(X)\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    945\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 946\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_seen_ \u001b[39m=\u001b[39m _incremental_mean_and_var(\n\u001b[0;32m    947\u001b[0m             X,\n\u001b[0;32m    948\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean_,\n\u001b[0;32m    949\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvar_,\n\u001b[0;32m    950\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_samples_seen_,\n\u001b[0;32m    951\u001b[0m             sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    952\u001b[0m         )\n\u001b[0;32m    954\u001b[0m \u001b[39m# for backward-compatibility, reduce n_samples_seen_ to an integer\u001b[39;00m\n\u001b[0;32m    955\u001b[0m \u001b[39m# if the number of samples is the same for each feature (i.e. no\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[39m# missing values)\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mptp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_seen_) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:1065\u001b[0m, in \u001b[0;36m_incremental_mean_and_var\u001b[1;34m(X, last_mean, last_variance, last_sample_count, sample_weight)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     new_unnormalized_variance \u001b[39m=\u001b[39m _safe_accumulator_op(\n\u001b[0;32m   1062\u001b[0m         np\u001b[39m.\u001b[39mmatmul, sample_weight, np\u001b[39m.\u001b[39mwhere(X_nan_mask, \u001b[39m0\u001b[39m, temp)\n\u001b[0;32m   1063\u001b[0m     )\n\u001b[0;32m   1064\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1065\u001b[0m     correction \u001b[39m=\u001b[39m _safe_accumulator_op(sum_op, temp, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m   1066\u001b[0m     temp \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m   1067\u001b[0m     new_unnormalized_variance \u001b[39m=\u001b[39m _safe_accumulator_op(sum_op, temp, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:963\u001b[0m, in \u001b[0;36m_safe_accumulator_op\u001b[1;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m     result \u001b[39m=\u001b[39m op(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 963\u001b[0m     result \u001b[39m=\u001b[39m op(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    964\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnansum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:722\u001b[0m, in \u001b[0;36mnansum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_nansum_dispatcher)\n\u001b[0;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnansum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m    625\u001b[0m            initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m    626\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[39m    Return the sum of array elements over a given axis treating Not a\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39m    Numbers (NaNs) as zero.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    720\u001b[0m \n\u001b[0;32m    721\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 722\u001b[0m     a, mask \u001b[39m=\u001b[39m _replace_nan(a, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m    723\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, keepdims\u001b[39m=\u001b[39mkeepdims,\n\u001b[0;32m    724\u001b[0m                   initial\u001b[39m=\u001b[39minitial, where\u001b[39m=\u001b[39mwhere)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:107\u001b[0m, in \u001b[0;36m_replace_nan\u001b[1;34m(a, val)\u001b[0m\n\u001b[0;32m    104\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(a, subok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    108\u001b[0m     np\u001b[39m.\u001b[39mcopyto(a, val, where\u001b[39m=\u001b[39mmask)\n\u001b[0;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m a, mask\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.43 GiB for an array with shape (50542, 9096) and data type float64"
     ]
    }
   ],
   "source": [
    "model = RegressionFactory.get_model(RegressionModels.DECISION_TREE)\n",
    "\n",
    "model.train(x_train=x_train,x_val=x_val,t_train=t_train,t_val=t_val)\n",
    "pred = model.predict(x_val=accorderie)\n",
    "print(pred)\n",
    "# model.cross_validate_model_performance(x_train=x_train,t_train=t_train, cv=5)\n",
    "# model.cross_validate_prediction(x_val=x_train,t_val=t_train)\n",
    "# model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LasoRegressione Model\n",
      "err:  0.3403819186490959\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionFactory.get_model(RegressionModels.LASO)\n",
    "\n",
    "model.train(x_train=x_train,x_val=x_val,t_train=t_train,t_val=t_val)\n",
    "pred = model.predict(x_val=accorderie)\n",
    "print(pred)\n",
    "# model.cross_validate_model_performance(x_train=x_train,t_train=t_train)\n",
    "# model.cross_validate_prediction(x_val=x_val,t_val=t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RegressionFactory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m RegressionFactory\u001b[39m.\u001b[39mget_model(RegressionModels\u001b[39m.\u001b[39mRANDOM_FOREST)\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39mtrain(x_train\u001b[39m=\u001b[39mx_train,x_val\u001b[39m=\u001b[39mx_val,t_train\u001b[39m=\u001b[39mt_train,t_val\u001b[39m=\u001b[39mt_val)\n\u001b[0;32m      4\u001b[0m \u001b[39m# # model.predict(x_val=accorderie)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# model.cross_validate_model_performance(x_train=x_train,t_train=t_train)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# model.cross_validate_prediction(x_val=x_val,t_val=t_val)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RegressionFactory' is not defined"
     ]
    }
   ],
   "source": [
    "model = RegressionFactory.get_model(RegressionModels.RANDOM_FOREST)\n",
    "\n",
    "model.train(x_train=x_train,x_val=x_val,t_train=t_train,t_val=t_val)\n",
    "pred = model.predict(x_val=accorderie)\n",
    "print(pred)\n",
    "# model.cross_validate_model_performance(x_train=x_train,t_train=t_train)\n",
    "# model.cross_validate_prediction(x_val=x_val,t_val=t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeRegressionl\n",
      "err:  6.734804859800597e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionFactory.get_model(RegressionModels.RIDGE)\n",
    "\n",
    "model.train(x_train=x_train,x_val=x_val,t_train=t_train,t_val=t_val)\n",
    "# model.predict(x_val=accorderie)\n",
    "# model.cross_validate_model_performance(x_train=x_train,t_train=t_train)\n",
    "# model.cross_validate_prediction(x_val=x_val,t_val=t_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5e2dd1cbe1f4896ca9eed4774742727d8fbcd7dc034097265272ce394987b5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
